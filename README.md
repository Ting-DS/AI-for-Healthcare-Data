# AI-for-Healthcare-Nanodegree

#### [Certification Link](https://www.udacity.com/certificate/e/89d29302-de3f-11ee-bf00-9b008d3aab47)

<div align="center">
  <img src="https://github.com/Ting-DS/AI-for-Healthcare-Nanodegree/blob/main/certification.png" width="80%">
</div>

## Introduction
This repository contains four Healthcare Data Science projects using AI techniques created by [Ting Lu](https://www.linkedin.com/in/ting-lu-9949b0233/):

 - [2D Image Classification: Pneumonia Detection from Chest X-Rays](): Analyze data from the [NIH Chest X-ray Dataset](https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community), including 112,000 chest x-rays with disease labels acquired from 30,000 patients, and train a CNN to predict the presence of pneumonia. Finally, prepare a FDA submission for [510(k) clearance](https://www.fda.gov/medical-devices/device-approvals-and-clearances/510k-clearances) as a medical device software. In addition to model development, the submission preparation will include model description, data introduction, and a validation plan compliant with FDA standards.

 - [3D Brain MRIs Segmentation: Quantifying Hippocampus Volume for Alzheimer's Progression]():
   
 - [STEDI Human Balance Analytics- Data Lakehouse solution](): Construct a lakehouse solution with landing, trusted, and curated data lake zones in AWS, utilizing Spark, Python, Glue Studio, S3, and Athena to address the STEDI data scientists' requirements.

 - [Automatic Data Pipeline with Apache Airflow](): Design, automate and monitor ETL pipelines in Apache Airflow for processing JSON logs and metadata from AWS S3 into Redshift data warehouse, involving custom operators for staging, data loading, and data quality checks, to create versatile ETL pipelines with monitoring and backfill capabilities.
